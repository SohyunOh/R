x = 1
install.packages('Rserve')
library(Rserve)
Rserve(FALSE, port = 6311, args = '--RS-encoding utf8 --no-save --slave --encoding utf8 --internet2')
Rserve(args = "--RS- encoding utf8")
Rserve(args = "--RS- encoding utf8")
r코드
mean( c(10,20,30,40) )
paste('hello','word')
c('hi','bye','빠이!')
setwd("D:\\spring\\upload")
library(ggplot2)
mpg <- as.data.frame(mpg)
png(width = 500 , height = 500, filename = '파일이름.png')
ggplot(mpg, aes( x= class, fill= class )) + geom_bar()
graphics.off()
print(png(width = 500 , height = 500, filename = '파일이름.png'))
print(ggplot(mpg, aes( x= class, fill= class )) + geom_bar())
print(graphics.off())
print(png(width = 500 , height = 500, filename = 're파일이름.png'))
print(ggplot(mpg, aes( x= class, fill= class )) + geom_bar())
print(graphics.off())
library(ggplot2)
library(dplyr)
mapg <-  as.data.frame(mpg)
as.data.frame(mpg) %>%
group_by(manufacturer)
as.data.frame(mpg) %>%
group_by(manufacturer) +
summarise(mean_hwy = mean(hwy))
mpg <-  as.data.frame(mpg)
as.data.frame(mpg) %>%
group_by(manufacturer) +
summarise(mean_hwy = mean(hwy))
as.data.frame(mpg) %>%
group_by(manufacturer) %>%
summarise(mean_hwy = mean(hwy))
d1 <- as.data.frame(mpg) %>%
group_by(manufacturer) %>%
summarise(mean_hwy = mean(hwy))
ggplot(d1, aes(x = reorder( manufacturer , mean_hwy ) , y = mean_hwy , fill=manufacturer  ) ) +geom_col()
ggplot(d1, aes(x = reorder( manufacturer , mean_hwy ) , y = mean_hwy , fill=manufacturer  ) ) +geom_col() +coord_flip()
png(width = 500 , height = 500 , filename = 'd1')
ggplot(d1, aes(x = reorder( manufacturer , mean_hwy ) , y = mean_hwy , fill=manufacturer  ) ) +geom_col() +coord_flip()
graphics.off()
print(png(width = 500 , height = 500 , filename = 'd1'))
print(ggplot(d1, aes(x = reorder( manufacturer , mean_hwy ) , y = mean_hwy , fill=manufacturer  ) ) +geom_col() +coord_flip())
print(graphics.off())
print(png(width = 500 , height = 500 , filename = 'd1.png'))
print(ggplot(d1, aes(x = reorder( manufacturer , mean_hwy ) , y = mean_hwy , fill=manufacturer  ) ) +geom_col() +coord_flip())
print(graphics.off())
install.packages("rJava")
install.packages("multilinguer")
library(rJava)
library(multilinguer)
# 의존성 패키지 설치
install.packages(c('stringr', 'hash', 'tau', 'Sejong', 'RSQLite', 'devtools'), type = "binary")
# github 버전 설치
install.packages("remotes")
# github 버전 설치
install.packages("remotes")
install.packages("remotes")
remotes::install_github('haven-jeon/KoNLP', upgrade = "never", INSTALL_opts=c("--no-multiarch"))
library(KoNLP) #확인 -> 없는 패키지 설치후 재 업로드
useNIADic() #사전 업로드
# 64bit 에서만 동작합니다.
remotes::install_github('haven-jeon/KoNLP', upgrade = "never", INSTALL_opts=c("--no-multiarch"))
library(KoNLP) #확인 -> 없는 패키지 설치후 재 업로드
useNIADic() #사전 업로드
useNIADic() #사전 업로드
#분석절차===================
#1. 데이터를 한줄씩 읽습니다
sng <- readLines("data/song.txt")
library(rJava)
sng <- readLines("data/song.txt")
#분석절차===================
#1. 데이터를 한줄씩 읽습니다
song <- readLines("data/song.txt")
#2.string 패키지를 이용해서 큭수문자를 제거
library(stringr)
#분석절차===================
#1. 데이터를 한줄씩 읽습니다
song <- readLines("data/song.txt")
#문자에서 명사를 추출
extractNoun("동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세 무궁화 삼천리 화려강산 대한사람 대한으로 길이 보전하세")
getwd()
setwd("D:\\R\\basic_r\\data")
song <- readLines("data/song.txt")
setwd("D:\\R\\basic_r")
song <- readLines("data/song.txt")
song
#2.string 패키지를 이용해서 큭수문자를 제거 (\\w는 R정규표현식에서 특수문자를 의미미)
library(stringr)
snog <- str_replace_all(hiphop, "\\W", " ") # R정규표현식 특수문자를 의미
#문자에서 명사를 추출
extractNoun("동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세 무궁화 삼천리 화려강산 대한사람 대한으로 길이 보전하세")
#3. 명사 추출
song_list <-extractNoun(song)
song_list
class(song_list)
#4. unlist함수를 이용해서 vertor형으로 형변환
song_vec <- unlist(song_list)
song_vec
class(song_vec)
#5. vector 형에서 분석을 위해 dataframe으로 변경
song_df <- as.data.frame(song_vec)
head(song_df)
head(song_df)
#6. 분석
library(dplyr)
rename(song_df, word = song_vec )
song_df <- rename(song_df, word = song_vec )
head(song_df)
#7. 분석 (단어의 자주사용된 빈도를 내림차순 정렬)
song_df %>%
group_by(word) %>%
summarise(feq =n())
#7. 분석 (단어의 자주사용된 빈도를 내림차순 정렬)
song_df %>%
fillter(nchar(word))
#7. 분석 (단어의 자주사용된 빈도를 내림차순 정렬)
song_df %>%
filter(nchar(word))
#7. 분석 (단어의 자주사용된 빈도를 내림차순 정렬)
song_df %>%
filter(nchar(word)) %>%
group_by(word) %>%
summarise(feq =n())
#7. 분석 (단어의 자주사용된 빈도를 내림차순 정렬)
song_df %>%
filter(nchar(word) >= 2) %>%
group_by(word) %>%
summarise(feq =n())
#7. 분석 (딜이가 2 이상의 단어의 자주사용된 빈도를 내림차순 정렬)
song_df %>%
filter(nchar(word) >= 2) %>%
group_by(word) %>%
summarise(feq =n()) %>%
arrange(desc(feq))
#7. 분석 (딜이가 2 이상의 단어의 자주사용된 빈도를 내림차순 정렬)
result <- song_df %>%
filter(nchar(word) >= 2) %>%
group_by(word) %>%
summarise(feq =n()) %>%
arrange(desc(feq))
str(result)
View(result)
#8. wordcloud 설치
install.packages("wordcloud")
library(wordcloud)
library(RColorBrewer)
# 색상목록을 추출
?brewer
brewer.pal( 8 , "Accent")
brewer.pal(12, "Set3")
color <- brewer.pal(12, "Set3")
wordcloud( words = result$word,
freq = result$feq,
min.freq = 2,
max.words = 200,
random.order = F,
rot.per = 0.1,
scale = c(4, 0.5),
colors = color
)
wordcloud( words = result$word,
freq = result$feq,
min.freq = 2,
max.words = 200,
random.order = F,
rot.per = 0.1,
scale = c(4, 0.2),
colors = color
)
wordcloud( words = result$word,
freq = result$feq,
min.freq = 2,
max.words = 200,
random.order = F,
rot.per = 0.1,
scale = c(4, 0.3),
colors = color
)
wordcloud( words = result$word,
freq = result$feq,
min.freq = 2,
max.words = 200,
random.order = F,
rot.per = 0.1,
scale = c(4, 0.3),
colors = color
)
wordcloud( words = result$word,
freq = result$feq,
min.freq = 2,
max.words = 200,
random.order = F,
rot.per = 0.1,
scale = c(4, 0.3),
colors = color
)
color <- brewer.pal(8, "Set2")
wordcloud( words = result$word,
freq = result$feq,
min.freq = 2,
max.words = 200,
random.order = F,
rot.per = 0.1,
scale = c(4, 0.3),
colors = color
)
wordcloud( words = result$word,
freq = result$feq,
min.freq = 2,
max.words = 200,
random.order = F,
rot.per = 0.1,
scale = c(3, 0.3),
colors = color
)
),
wordcloud( words = result$word,
freq = result$feq,
min.freq = 2,
max.words = 200,
random.order = F,
rot.per = 0.1,
scale = c(3, 0.3),
colors = color
)
wordcloud( words = result$word,
freq = result$feq,
min.freq = 2,
max.words = 200,
random.order = F,
rot.per = 0.1,
scale = c(3, 0.3),
colors = color
)
wordcloud( words = result$word,
freq = result$feq,
min.freq = 2,
max.words = 200,
random.order = F,
rot.per = 0.1,
scale = c(3, 0.3),
colors = color
)
wordcloud( words = result$word, #적용시킬 단어
freq = result$feq, #빈도
min.freq = 2, #최소단어 빈도
max.words = 200, #표현할 단어 수
random.order = F, #고빈도 단어 중앙배치 (f중앙, t 랜덤)
rot.per = 0.1, #단어회전 비율
scale = c(3, 0.3), # 단어 크기 (중앙, 끝)
colors = color #색상상
)
set.seed(1234)
wordcloud( words = result$word, #적용시킬 단어
freq = result$feq, #빈도
min.freq = 2, #최소단어 빈도
max.words = 200, #표현할 단어 수
random.order = F, #고빈도 단어 중앙배치 (f중앙, t 랜덤)
rot.per = 0.1, #단어회전 비율
scale = c(3, 0.3), # 단어 크기 (중앙, 끝)
colors = color #색상
)
set.seed(1234)
wordcloud( words = result$word, #적용시킬 단어
freq = result$feq, #빈도
min.freq = 2, #최소단어 빈도
max.words = 200, #표현할 단어 수
random.order = F, #고빈도 단어 중앙배치 (f중앙, t 랜덤)
rot.per = 0.1, #단어회전 비율
scale = c(3, 0.3), # 단어 크기 (중앙, 끝)
colors = color #색상
)
set.seed(1234)
wordcloud( words = result$word, #적용시킬 단어
freq = result$feq, #빈도
min.freq = 2, #최소단어 빈도
max.words = 200, #표현할 단어 수
random.order = F, #고빈도 단어 중앙배치 (f중앙, t 랜덤)
rot.per = 0.1, #단어회전 비율
scale = c(3, 0.3), # 단어 크기 (중앙, 끝)
colors = color #색상
)
